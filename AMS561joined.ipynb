{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PyTorch for NN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = pd.read_csv('lda_eprec6.csv')\n",
    "pbe0 = pd.read_csv('pbe0_eprec6.csv')\n",
    "# go through input files in geometry folder and parse geometry block into dictonary mols\n",
    "#\n",
    "# get relative path assuming geometries are in separate folder in the same directory\n",
    "path = os.path.abspath(os.getcwd())\n",
    "geometries_path = os.path.join(path, 'geometries')\n",
    "mols = {}\n",
    "# if relative path doesn't work use absolute path instead\n",
    "#for filename in os.scandir(\"/home/hannes/Documents/SBU/AMS561/ML/geometries\"):\n",
    "for filename in os.scandir(geometries_path):\n",
    "    # parse name of molecule (filename) for key\n",
    "    # does not distinguish files - make sure ONLY mdns files are in director\n",
    "    # e.g. no swap files from editors\n",
    "    name = str(filename).split()[1]\n",
    "    name = name.replace('.mdns', '')\n",
    "    name = name.replace(\"'\", \"\")\n",
    "    name = name.replace(\">\", \"\")\n",
    "    if filename.is_file():\n",
    "        f = open(filename, \"r\")\n",
    "        # list of lists containing [letter, x, y, z]\n",
    "        mol = []\n",
    "        # the format is\n",
    "        # geometry\n",
    "        # units angstrom\n",
    "        #  H 0 0 0\n",
    "        #  ...\n",
    "        # end\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            # skip the angstrom and geometry lines (not very clean but works for now)\n",
    "            if \"geometry\" in line:\n",
    "                line = f.readline()\n",
    "                #if \"units angstrom\" in line:\n",
    "                 #   f.readline()\n",
    "                while True:\n",
    "                    line = f.readline()\n",
    "                    if line == \"end\":\n",
    "                        break\n",
    "                    mol.append(line.split())\n",
    "                mols[name] = mol \n",
    "                #print(len(mol))       \n",
    "            if not line:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = {\n",
    "    \"H\": 1,\n",
    "    \"He\": 2,\n",
    "    \"Li\": 3,\n",
    "    \"Be\": 4,\n",
    "    \"B\": 5,\n",
    "    \"C\": 6,\n",
    "    \"N\": 7,\n",
    "    \"O\": 8,\n",
    "    \"F\": 9,\n",
    "    \"Ne\": 10,\n",
    "    \"Na\": 11,\n",
    "    \"Mg\": 12,\n",
    "    \"Al\": 13,\n",
    "    \"Si\": 14,\n",
    "    \"P\": 15,\n",
    "    \"S\": 16,\n",
    "    \"Cl\": 17,\n",
    "    \"Ar\": 18,\n",
    "    \"K\": 19,\n",
    "    \"Ca\": 20,\n",
    "    \"Sc\": 21,\n",
    "    \"Ti\": 22,\n",
    "    \"V\": 23,\n",
    "    \"Cr\": 24,\n",
    "    \"Mn\": 25,\n",
    "    \"Fe\": 26,\n",
    "    \"Co\": 27,\n",
    "    \"Ni\": 28,\n",
    "    \"Cu\": 29,\n",
    "    \"Zn\": 30,\n",
    "    \"Ga\": 31,\n",
    "    \"Ge\": 32,\n",
    "    \"As\": 33,\n",
    "    \"Se\": 34,\n",
    "    \"Br\": 35,\n",
    "    \"Kr\": 36,\n",
    "    \"Rb\": 37,\n",
    "    \"Sr\": 38,\n",
    "    \"Y\": 39,\n",
    "    \"Zr\": 40,\n",
    "    \"Nb\": 41,\n",
    "    \"Mo\": 42,\n",
    "    \"Tc\": 43,\n",
    "    \"Ru\": 44,\n",
    "    \"Rh\": 45,\n",
    "    \"Pd\": 46,\n",
    "    \"Ag\": 47,\n",
    "    \"Cd\": 48,\n",
    "    \"In\": 49,\n",
    "    \"Sn\": 50,\n",
    "    \"Sb\": 51,\n",
    "    \"Te\": 52,\n",
    "    \"I\": 53,\n",
    "    \"Xe\": 54,\n",
    "    \"Cs\": 55,\n",
    "    \"Ba\": 56,\n",
    "    \"La\": 57,\n",
    "    \"Ce\": 58,\n",
    "    \"Pr\": 59,\n",
    "    \"Nd\": 60,\n",
    "    \"Pm\": 61,\n",
    "    \"Sm\": 62,\n",
    "    \"Eu\": 63,\n",
    "    \"Gd\": 64,\n",
    "    \"Tb\": 65,\n",
    "    \"Dy\": 66,\n",
    "    \"Ho\": 67,\n",
    "    \"Er\": 68,\n",
    "    \"Tm\": 69,\n",
    "    \"Yb\": 70,\n",
    "    \"Lu\": 71,\n",
    "    \"Hf\": 72,\n",
    "    \"Ta\": 73,\n",
    "    \"W\": 74,\n",
    "    \"Re\": 75,\n",
    "    \"Os\": 76,\n",
    "    \"Ir\": 77,\n",
    "    \"Pt\": 78,\n",
    "    \"Au\": 79,\n",
    "    \"Hg\": 80\n",
    "}\n",
    "def distance(coord1, coord2):\n",
    "    return np.linalg.norm(coord1 - coord2)\n",
    "dimension=32\n",
    "def get_charge(symbol):\n",
    "    return elements[symbol]\n",
    "\n",
    "def coulomb_matrix(molecule):\n",
    "    num_atoms = len(molecule)\n",
    "    coords = np.array([[float(atom[1]), float(atom[2]), float(atom[3])] for atom in molecule])\n",
    "    charges = np.array([get_charge(atom[0]) for atom in molecule])\n",
    "    \n",
    "    coulomb_mat = np.zeros((dimension, dimension))\n",
    "    \n",
    "    for i in range(num_atoms):\n",
    "        for j in range(num_atoms):\n",
    "            if i == j:\n",
    "                coulomb_mat[i, j] = 0.5 * charges[i] ** 2.4\n",
    "            else:\n",
    "                coulomb_mat[i, j] = charges[i] * charges[j] / distance(coords[i], coords[j])\n",
    "    \n",
    "    return coulomb_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols_dict = {}\n",
    "\n",
    "for item in mols.items():\n",
    "    mols_dict[item[0]] = coulomb_matrix(item[1]).flatten() \n",
    "    #mols_vec.append(coulomb_matrix(item[1]).flatten())\n",
    "    \n",
    "y_test = pbe0['Energy'].astype(float)-lda['Energy'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols_vec = []\n",
    "energy_diff = []\n",
    "for i in pbe0['Unnamed: 0']:\n",
    "    mols_vec.append(mols_dict[i])\n",
    "\n",
    "input_vector = np.array(mols_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-test, y-test are 225 data points, remove first element for verification\n",
    "x_verification = []\n",
    "x_verification.append(input_vector[0])\n",
    "y_verification = y_test[0]\n",
    "\n",
    "x_input = input_vector[1:]\n",
    "y_input = []\n",
    "for i in y_test[1:]:\n",
    "    y_input.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.5435, Val Loss: 13.7104\n",
      "Epoch [20/1000], Loss: 0.6018, Val Loss: 6.0379\n",
      "Early stopping on epoch 24.\n",
      "Predicted output: -1.6381014585494995\n",
      "True output: -1.9075102999999842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37626/813123339.py:76: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  input_data = torch.tensor(x_verification)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Input data\n",
    "X = torch.tensor(x_input.tolist())\n",
    "Y = torch.tensor(y_input)\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2,random_state=42)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Define the model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = len(x_input[0])\n",
    "model = NeuralNet(input_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "counter = 0\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "    loss = criterion(outputs.squeeze(), Y_train)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation loss\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(torch.tensor(X_val, dtype=torch.float32))\n",
    "        val_loss = criterion(val_outputs.squeeze(), Y_val)\n",
    "        \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}.')\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Test\n",
    "input_data = torch.tensor(np.array(x_verification))\n",
    "input_data = scaler.transform(input_data) # Normalize\n",
    "predicted_output = model(torch.tensor(input_data, dtype=torch.float32))\n",
    "print(\"Predicted output:\", predicted_output.item())\n",
    "print(\"True output:\", y_verification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.13434163\n",
      "Validation MSE: 1.1032469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def calculate_mse(model, X, Y):\n",
    "    outputs = model(torch.tensor(X, dtype=torch.float32))\n",
    "    loss = mean_squared_error(outputs.squeeze().detach().numpy(), Y)\n",
    "    return loss\n",
    "\n",
    "train_mse = calculate_mse(model, X_train, Y_train)\n",
    "print(\"Training MSE:\", train_mse)\n",
    "\n",
    "val_mse = calculate_mse(model, X_val, Y_val)\n",
    "print(\"Validation MSE:\", val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb504e06e19e8d88e2fb0eed19ec0a704236ef277cc2f7218769018cf6791d95"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
